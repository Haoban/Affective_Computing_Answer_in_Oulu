{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# The contents of this file are in the public domain. See LICENSE_FOR_EXAMPLE_PROGRAMS.txt\n",
    "#\n",
    "#   This example program shows how to find frontal human faces in an image and\n",
    "#   estimate their pose.  The pose takes the form of 68 landmarks.  These are\n",
    "#   points on the face such as the corners of the mouth, along the eyebrows, on\n",
    "#   the eyes, and so forth.\n",
    "#\n",
    "#   The face detector we use is made using the classic Histogram of Oriented\n",
    "#   Gradients (HOG) feature combined with a linear classifier, an image pyramid,\n",
    "#   and sliding window detection scheme.  The pose estimator was created by\n",
    "#   using dlib's implementation of the paper:\n",
    "#      One Millisecond Face Alignment with an Ensemble of Regression Trees by\n",
    "#      Vahid Kazemi and Josephine Sullivan, CVPR 2014\n",
    "#   and was trained on the iBUG 300-W face landmark dataset (see\n",
    "#   https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/):  \n",
    "#      C. Sagonas, E. Antonakos, G, Tzimiropoulos, S. Zafeiriou, M. Pantic. \n",
    "#      300 faces In-the-wild challenge: Database and results. \n",
    "#      Image and Vision Computing (IMAVIS), Special Issue on Facial Landmark Localisation \"In-The-Wild\". 2016.\n",
    "#   You can get the trained model file from:\n",
    "#   http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2.\n",
    "#   Note that the license for the iBUG 300-W dataset excludes commercial use.\n",
    "#   So you should contact Imperial College London to find out if it's OK for\n",
    "#   you to use this model file in a commercial product.\n",
    "#\n",
    "#\n",
    "#   Also, note that you can train your own models using dlib's machine learning\n",
    "#   tools. See train_shape_predictor.py to see an example.\n",
    "#\n",
    "#\n",
    "# COMPILING/INSTALLING THE DLIB PYTHON INTERFACE\n",
    "#   You can install dlib using the command:\n",
    "#       pip install dlib\n",
    "#\n",
    "#   Alternatively, if you want to compile dlib yourself then go into the dlib\n",
    "#   root folder and run:\n",
    "#       python setup.py install\n",
    "#\n",
    "#   Compiling dlib should work on any operating system so long as you have\n",
    "#   CMake installed.  On Ubuntu, this can be done easily by running the\n",
    "#   command:\n",
    "#       sudo apt-get install cmake\n",
    "#\n",
    "#   Also note that this example requires Numpy which can be installed\n",
    "#   via the command:\n",
    "#       pip install numpy\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "\n",
    "if len(sys.argv) != 3:\n",
    "    print(\n",
    "        \"Give the path to the trained shape predictor model as the first \"\n",
    "        \"argument and then the directory containing the facial images.\\n\"\n",
    "        \"For example, if you are in the python_examples folder then \"\n",
    "        \"execute this program by running:\\n\"\n",
    "        \"    ./face_landmark_detection.py shape_predictor_68_face_landmarks.dat ../examples/faces\\n\"\n",
    "        \"You can download a trained facial shape predictor from:\\n\"\n",
    "        \"    http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "    exit()\n",
    "\n",
    "predictor_path = sys.argv[1]\n",
    "faces_folder_path = sys.argv[2]\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "win = dlib.image_window()\n",
    "\n",
    "for f in glob.glob(os.path.join(faces_folder_path, \"*.jpg\")):\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    img = dlib.load_rgb_image(f)\n",
    "\n",
    "    win.clear_overlay()\n",
    "    win.set_image(img)\n",
    "\n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces.\n",
    "    dets = detector(img, 1)\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "    for k, d in enumerate(dets):\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "        # Get the landmarks/parts for the face in box d.\n",
    "        shape = predictor(img, d)\n",
    "        print(\"Part 0: {}, Part 1: {} ...\".format(shape.part(0),\n",
    "                                                  shape.part(1)))\n",
    "        # Draw the face landmarks on the screen.\n",
    "        win.add_overlay(shape)\n",
    "\n",
    "    win.add_overlay(dets)\n",
    "    dlib.hit_enter_to_continue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
